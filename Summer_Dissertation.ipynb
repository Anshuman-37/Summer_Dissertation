{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summer_Dissertation.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMvHA6NgSpCzC5E22wAcPZH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anshuman-37/Summer_Dissertation/blob/main/Summer_Dissertation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prerequisites "
      ],
      "metadata": {
        "id": "v65d0HQdUmgQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgmFd3fhUO8A"
      },
      "outputs": [],
      "source": [
        "# Upload the zip file and then unzip it\n",
        "# unzipping the file in the directory \n",
        "!unzip /content/Raw\\ Files.zip -d /content/\n",
        "!unzip /content/Baseline.zip -d /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing Libraries"
      ],
      "metadata": {
        "id": "wvl6QPt6Umoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install nibabel\n",
        "!pip install nibabel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZYKydviUmGH",
        "outputId": "b5abecce-8097-487a-b3b8-b1cb00d964fd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from nibabel) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Files "
      ],
      "metadata": {
        "id": "KR9SgttLUrqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## importing libraries \n",
        "import os\n",
        "import re\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "Y6YbyNa7XlZL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code"
      ],
      "metadata": {
        "id": "GiyjwEXtXl_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading the Data"
      ],
      "metadata": {
        "id": "MsunshWfGnCl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Getting path of data"
      ],
      "metadata": {
        "id": "LgPb9y7XGwjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Go in to the directories\n",
        "## Extracting only important data using Regex\n",
        "path = '/content/Raw Files/Raw_nii_files_for_MC_pCASL_T1_B0_M0/'\n",
        "regex = re.compile(r'__MPR.*') ; fileRegex1 = re.compile(r'(WIP)*T13D'); mri_data_path = []; \n",
        "\n",
        "# Iterating over Directories \n",
        "for subdir, dirs, files in os.walk(path):\n",
        "    for file in files:\n",
        "        # Storing the path of Data\n",
        "        if regex.search(file) == None:\n",
        "            if fileRegex1.search(file): mri_data_path.append(os.path.join(subdir, file));\n",
        "# Printing the path of Data\n",
        "for i in mri_data_path: print(i); "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BukdfqflVbnX",
        "outputId": "ff5bab50-1ac6-41d5-952a-770c4ddb5aa3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Raw Files/Raw_nii_files_for_MC_pCASL_T1_B0_M0/1291194 dicom/__WIP_MPRAGE_T13D_SENSE_20150724132211_401.nii\n",
            "/content/Raw Files/Raw_nii_files_for_MC_pCASL_T1_B0_M0/1277547 dicom/__WIP_MPRAGE_T13D_SENSE_20150430160250_401.nii\n",
            "/content/Raw Files/Raw_nii_files_for_MC_pCASL_T1_B0_M0/1289317 dicom/__WIP_MPRAGE_T13D_SENSE_20150710135121_401.nii\n",
            "/content/Raw Files/Raw_nii_files_for_MC_pCASL_T1_B0_M0/1327832 dicom/__WIP_MPRAGE_T13D_SENSE_20160222133236_301.nii\n",
            "/content/Raw Files/Raw_nii_files_for_MC_pCASL_T1_B0_M0/1320961 dicom/__WIP_MPRAGE_T13D_SENSE_20160115152740_301.nii\n",
            "/content/Raw Files/Raw_nii_files_for_MC_pCASL_T1_B0_M0/1335478 dicom/__WIP_MPRAGE_T13D_SENSE_20160407112645_401.nii\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Loading data using nibabel"
      ],
      "metadata": {
        "id": "4ZknomRiG5-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mri_images = []\n",
        "\n",
        "# Loading data in the image vector\n",
        "for i in mri_data_path: mri_images.append(nib.load(i)); \n",
        "\n",
        "# Printing the shape of images stored and its data type\n",
        "for i in mri_images: print('Image shape ->',i.shape,end = '\\t'); print('Image Data Type ->',i.get_data_dtype());"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7VUVypHG5ak",
        "outputId": "569cd16e-0f3d-49f8-c7d3-67609a04522a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape -> (288, 288, 180)\tImage Data Type -> int16\n",
            "Image shape -> (288, 288, 180)\tImage Data Type -> int16\n",
            "Image shape -> (288, 288, 180)\tImage Data Type -> int16\n",
            "Image shape -> (288, 288, 180)\tImage Data Type -> int16\n",
            "Image shape -> (288, 288, 180)\tImage Data Type -> int16\n",
            "Image shape -> (288, 288, 180)\tImage Data Type -> int16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Discussions -\n",
        "\n",
        "1. - The Data that is loaded right now is our X(Attribute) and Y should be our ASL Measured Data\n",
        "2. - The nii files are a 3D tensor with some values ranging between 0-400k (IDK what it is but we need to ask her in the next meeting)\n",
        "\n",
        "\n",
        "###### Things we do next -\n",
        "1. - Try to normalize the Values of X first\n",
        "2. - Understanding Y (ASL data) is next\n",
        "3. - We write a model for using X to predict Y\n",
        "\n"
      ],
      "metadata": {
        "id": "cJ0WMw35NP6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(img.dataobj))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsfsjMjB4Q0P",
        "outputId": "4cdc9a0a-949c-411b-aafc-5b20f027be76"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'nibabel.arrayproxy.ArrayProxy'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Data Analysis "
      ],
      "metadata": {
        "id": "fFMaYWuHvMOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Reading the Data\n",
        "img = mri_images[0]\n",
        "a = np.array(img.dataobj)[:,:,np.newaxis,:] # Batch Size x Time x Channels x Height x Width\n",
        "# Image - > Hight x Width x Channels x Time \n",
        "## Use to check whether there is anything there or not\n",
        "print(type(a), a.shape)\n",
        "# Getting maximum values from the np array\n",
        "a_max = np.amax(a); a_min = np.amin(a);\n",
        "print(a_max); print(a_min);  # To ask where this maximum value comming from"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fzBs5LiATZZ",
        "outputId": "1bdd4d75-601f-4d72-dc37-88dddff43d12"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> (288, 288, 1, 180)\n",
            "514092.99560546875\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Just checking the time taken to iterate over\n",
        "%timeit np.amin(a); \n",
        "%timeit np.amax(a); "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ez2TpU-nHFY",
        "outputId": "acf3c5aa-f2ef-48a0-ad41-8b1b0831ec2c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 loops, best of 5: 12.4 ms per loop\n",
            "100 loops, best of 5: 12.5 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Min max noramalization\n",
        "a = (a - a.min()) / (a.max() - a.min())\n",
        "\n",
        "## Printing to check whether the data has been normalized or not\n",
        "print(a[120,200,0,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzFDxdNqnsIZ",
        "outputId": "5d493e82-fb4d-4f66-ecb9-a1cadf459555"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08582089552238806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Plots of MRI Data \n"
      ],
      "metadata": {
        "id": "ylN72b9Lvfig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## To iterate over the MRI scan slices\n",
        "for i in range(0,179):\n",
        "    plt.imshow(a[:,:,0,i],cmap = 'gray')\n",
        "    plt.show()\n",
        "\n",
        "## To create the animation of the MRI images\n",
        "# import matplotlib.pyplot as plt\n",
        "# import matplotlib.cm as cm\n",
        "# import matplotlib.animation as animation\n",
        "\n",
        "# img = [] # some array of images\n",
        "# frames = [] # for storing the generated images\n",
        "# fig = plt.figure()\n",
        "# for i in range(0,179):\n",
        "#     #frames.append([plt.imshow((a[:,:,i]-a[:,:,i+1])**2, cmap=cm.Greys_r,animated=True)])\n",
        "#     frames.append([plt.imshow((a[:,:,i], cmap=cm.Greys_r,animated=True)])\n",
        "# ani = animation.ArtistAnimation(fig, frames, interval=50, blit=True, repeat_delay=1000)\n",
        "# ani.save('movie.mp4')"
      ],
      "metadata": {
        "id": "8trWE-ljve5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalized\n",
        "a_max = np.amax(a); a_min = np.amin(a);\n",
        "print(a_max); print(a_min);\n",
        "\n",
        "# Unique counts \n",
        "unique, counts = np.unique(a, return_counts=True)\n",
        "freq_counts = np.vstack(( unique, counts)).T\n",
        "print(freq_counts)\n",
        "\n",
        "## Uncomment to plot the graph\n",
        "# fig = plt.figure()\n",
        "# ax = fig.add_axes([0,0,1,1])\n",
        "# ax.bar(unique,counts)\n",
        "# # Most of the normalized values lies at less than <0.40 of maximum \n",
        "# # There is a lot of data imbalance  \n",
        "# plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "cIH1B4vsoDW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Discussions -\n",
        "\n",
        "1. - There is a huge unique data imbalance most of the values after noramzalization are below 40% of maximum value.\n",
        "\n",
        "2. - The data MRI data is kind of Time Series Data so we added one more dimension as channels and used time slices as the 4th dimension\n",
        "\n",
        "###### Things we do next -\n",
        "1. - Load Y\n",
        "2. - Understanding Y ASL data\n",
        "3. - Normalizing Y"
      ],
      "metadata": {
        "id": "O-gdtGQGvxSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OUw8nSWVwZFy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Reading the Target Data (ASL)"
      ],
      "metadata": {
        "id": "o-6w7iBOr_Nj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the path for ASL files\n",
        "asl_path = '/content/Baseline/'\n",
        "asl_data_path = []\n",
        "\n",
        "# Iterating over directories\n",
        "for subdir, dirs, files in os.walk(asl_path):\n",
        "    # Selecting the ASL file\n",
        "    for file in files:\n",
        "        if file == 'asldata.nii': asl_data_path.append(os.path.join(subdir, file));\n",
        "\n",
        "# Printing the path of ASL images\n",
        "for i in asl_data_path: print(i);\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgPPGY2opO4f",
        "outputId": "094008cc-a63b-4f8a-fcbb-e1afed8ed3df"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Baseline/1291194 dicom/analysis/asldata.nii\n",
            "/content/Baseline/1277547 dicom/analysis/asldata.nii\n",
            "/content/Baseline/1289317 dicom/analysis/asldata.nii\n",
            "/content/Baseline/1259089 dicom/sub0001/asldata.nii\n",
            "/content/Baseline/1327832 dicom/analysis/asldata.nii\n",
            "/content/Baseline/1320961 dicom/analysis/asldata.nii\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "asl_images = []\n",
        "\n",
        "# Loading data in the image vector\n",
        "for i in asl_data_path: asl_images.append(nib.load(i)); \n",
        "\n",
        "# Printing the shape of images stored and its data type\n",
        "for i in asl_images: print('Image shape ->',i.shape,end = '\\t'); print('Image Data Type ->',i.get_data_dtype());\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFKwifLEu350",
        "outputId": "bfb9ef1d-ecb7-4c8c-a168-67a407c13ef8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape -> (80, 80, 13, 60)\tImage Data Type -> int16\n",
            "Image shape -> (80, 80, 13, 60)\tImage Data Type -> int16\n",
            "Image shape -> (80, 80, 13, 60)\tImage Data Type -> int16\n",
            "Image shape -> (80, 80, 13, 60)\tImage Data Type -> int16\n",
            "Image shape -> (80, 80, 13, 60)\tImage Data Type -> int16\n",
            "Image shape -> (80, 80, 13, 60)\tImage Data Type -> int16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### EDA and Normalization of ASL DATA"
      ],
      "metadata": {
        "id": "mnL8r-9CvmPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Reading the Data\n",
        "img = asl_images[0]\n",
        "a = np.array(img.dataobj) # Dimensions -  Batch Size x Time x Channels x Height x Width\n",
        "# Dimensions we have - Height x Width x Part of Brain x Time(ASL) \n",
        "## Use to check whether there is anything there or not\n",
        "# print(a)\n",
        "\n",
        "# Getting maximum values from the np array\n",
        "a_max = np.amax(a); a_min = np.amin(a);\n",
        "print(a_max); print(a_min); \n",
        "\n",
        "# To iterate over the time series data of the ASL data for a specific slice of brain \n",
        "for i in range(0,59):\n",
        "    plt.imshow(a[:,:,12,i],cmap = 'gray')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "DFaRt_lWvkN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just checking the time taken to iterate over\n",
        "%timeit np.amin(a); \n",
        "%timeit np.amax(a); "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXa_2E8HwYpo",
        "outputId": "769525f0-4fa5-4e4d-d3ab-7ae7ee95e3e8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 loops, best of 5: 1.73 ms per loop\n",
            "1000 loops, best of 5: 1.86 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Min max noramalization\n",
        "a[:,:,:,:] = (a - a.min()) / (a.max() - a.min())"
      ],
      "metadata": {
        "id": "0Nct8JauwdUK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalized\n",
        "a_max = np.amax(a); a_min = np.amin(a);\n",
        "print(a_max); print(a_min);\n",
        "\n",
        "# Unique counts \n",
        "unique, counts = np.unique(a, return_counts=True)\n",
        "freq_counts = np.vstack(( unique, counts)).T\n",
        "print(freq_counts)\n",
        "\n",
        "\n",
        "# # Uncomment to plot the graph\n",
        "# fig = plt.figure()\n",
        "# ax = fig.add_axes([0,0,1,1])\n",
        "# ax.bar(unique,counts)\n",
        "# # Most of the normalized values lies at less than <0.40 of maximum \n",
        "# # There is a lot of data imbalance  \n",
        "# plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TqL8tJ8wgCY",
        "outputId": "8ced90f7-0ab6-40af-e4ba-173b62d24aa0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.0\n",
            "[[0.00000000e+00 8.40625000e+05]\n",
            " [9.22509225e-04 5.49038000e+05]\n",
            " [1.84501845e-03 3.28383000e+05]\n",
            " ...\n",
            " [9.98154982e-01 1.00000000e+00]\n",
            " [9.99077491e-01 1.00000000e+00]\n",
            " [1.00000000e+00 1.00000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Discussions -\n",
        "\n",
        "1. - The values of ASL are kind of similar after the min max normalization. This means we can train a model and get good results. \n",
        "\n",
        "2. - The ASL data has 60 images for a specific part of brain which is divided in 13 parts. i.e. in MRI data brain had a sequentail scan which was in 180 parts but in ASL data the sequential scan is reduced to 13 parts. Thus now we know what these dimensions mean in the data.\n",
        "\n",
        "###### Things we do next -\n",
        "1. - Try to make the data a bit more better \n",
        "2. - Understanding X and Y even better\n",
        "3. - Trying to make things a notch simpler"
      ],
      "metadata": {
        "id": "rPdTrn9zwu8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Making Training and Testing data"
      ],
      "metadata": {
        "id": "Vv4DQqreAVvZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Creating DATA dicts"
      ],
      "metadata": {
        "id": "MoFEq8qKDRY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('MRI DATA DICT \\t \\n','-'*50);\n",
        "### Data hashmaps - \n",
        "### Mri Data  ## Idea - Patient number(key) - Path Stored(value)\n",
        "mri_map = {};\n",
        "\n",
        "## Iterating over the mri data's path\n",
        "for i in mri_data_path:\n",
        "    ## Value is our path i.e. stored and key is the patient number\n",
        "    value = i; key = i.split('/')[4].split(' ')[0]; mri_map[key] = value;\n",
        "\n",
        "# Printing the mri_data_dict \n",
        "for k,v in mri_map.items(): print(k,'->',v);\n",
        "\n",
        "######\n",
        "print('\\nASL DATA DICT - \\t \\n','-'*50);\n",
        "######\n",
        "### ASL Data ## Idea - Patient number(key) - Path Stored(value)\n",
        "asl_map = {}\n",
        "\n",
        "## Iterating over the mri data's path\n",
        "for i in asl_data_path:\n",
        "    ## Value is our path i.e. stored and key is the patient number\n",
        "    value = i; key = i.split('/')[3].split(' ')[0]; asl_map[key] = value;\n",
        "\n",
        "# Printing the asl_data_dict \n",
        "for k,v in asl_map.items(): print(k,'->',v);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u9N1yDwAUv-",
        "outputId": "21150223-e5a5-4e52-9ffc-35484a6e8077"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MRI DATA DICT \t \n",
            " --------------------------------------------------\n",
            "1291194 -> /content/Raw Files/Raw_nii_files_for_MC_pCASL_T1_B0_M0/1291194 dicom/__WIP_MPRAGE_T13D_SENSE_20150724132211_401.nii\n",
            "1277547 -> /content/Raw Files/Raw_nii_files_for_MC_pCASL_T1_B0_M0/1277547 dicom/__WIP_MPRAGE_T13D_SENSE_20150430160250_401.nii\n",
            "1289317 -> /content/Raw Files/Raw_nii_files_for_MC_pCASL_T1_B0_M0/1289317 dicom/__WIP_MPRAGE_T13D_SENSE_20150710135121_401.nii\n",
            "1327832 -> /content/Raw Files/Raw_nii_files_for_MC_pCASL_T1_B0_M0/1327832 dicom/__WIP_MPRAGE_T13D_SENSE_20160222133236_301.nii\n",
            "1320961 -> /content/Raw Files/Raw_nii_files_for_MC_pCASL_T1_B0_M0/1320961 dicom/__WIP_MPRAGE_T13D_SENSE_20160115152740_301.nii\n",
            "1335478 -> /content/Raw Files/Raw_nii_files_for_MC_pCASL_T1_B0_M0/1335478 dicom/__WIP_MPRAGE_T13D_SENSE_20160407112645_401.nii\n",
            "\n",
            "ASL DATA DICT - \t \n",
            " --------------------------------------------------\n",
            "1291194 -> /content/Baseline/1291194 dicom/analysis/asldata.nii\n",
            "1277547 -> /content/Baseline/1277547 dicom/analysis/asldata.nii\n",
            "1289317 -> /content/Baseline/1289317 dicom/analysis/asldata.nii\n",
            "1259089 -> /content/Baseline/1259089 dicom/sub0001/asldata.nii\n",
            "1327832 -> /content/Baseline/1327832 dicom/analysis/asldata.nii\n",
            "1320961 -> /content/Baseline/1320961 dicom/analysis/asldata.nii\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Making Training Data X,Y"
      ],
      "metadata": {
        "id": "xwUFV8bjDV1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Lists to get train x and train y differently\n",
        "train_x = [] ; train_y = []; \n",
        "\n",
        "### Traversing over the map and getting the values for which asl data is present\n",
        "for k,v in mri_map.items():\n",
        "    if k in asl_map: train_x.append(v); train_y.append(asl_map[k]);\n",
        "\n",
        "## Printing train_x and train_y to get path stored\n",
        "for i in train_x: print(i);\n",
        "for i in train_y: print(i);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDwePweb67A0",
        "outputId": "4d66dcbd-b5ed-4a5a-c58b-267a5218a7bd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Raw Files/Raw_nii_files_for_MC_pCASL_T1_B0_M0/1291194 dicom/__WIP_MPRAGE_T13D_SENSE_20150724132211_401.nii\n",
            "/content/Raw Files/Raw_nii_files_for_MC_pCASL_T1_B0_M0/1277547 dicom/__WIP_MPRAGE_T13D_SENSE_20150430160250_401.nii\n",
            "/content/Raw Files/Raw_nii_files_for_MC_pCASL_T1_B0_M0/1289317 dicom/__WIP_MPRAGE_T13D_SENSE_20150710135121_401.nii\n",
            "/content/Raw Files/Raw_nii_files_for_MC_pCASL_T1_B0_M0/1327832 dicom/__WIP_MPRAGE_T13D_SENSE_20160222133236_301.nii\n",
            "/content/Raw Files/Raw_nii_files_for_MC_pCASL_T1_B0_M0/1320961 dicom/__WIP_MPRAGE_T13D_SENSE_20160115152740_301.nii\n",
            "/content/Baseline/1291194 dicom/analysis/asldata.nii\n",
            "/content/Baseline/1277547 dicom/analysis/asldata.nii\n",
            "/content/Baseline/1289317 dicom/analysis/asldata.nii\n",
            "/content/Baseline/1327832 dicom/analysis/asldata.nii\n",
            "/content/Baseline/1320961 dicom/analysis/asldata.nii\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Tensorflow"
      ],
      "metadata": {
        "id": "feCaSb2OAH3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def try_cnn():\n",
        "    inputs = tf.keras.Input(288, 288, 180)\n",
        "    "
      ],
      "metadata": {
        "id": "4bblp3S2AKVR"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Pytorch"
      ],
      "metadata": {
        "id": "GWjKJE6U66pw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Defining the model in torch\n",
        "class Unet_3D(torch.nn.Module):\n",
        "    ## Intializing the constructor\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Unet_3D, self).__init__()\n",
        "        ### Adding layers\n",
        "        self.conv1 = torch.nn.Conv3d(180, 160 ,(3,3,3))\n",
        "        self.activation = torch.nn.ReLU()\n",
        "        self.conv2 = torch.nn.Conv3d(160,80,(3,3,3))\n",
        "        self.softmax = torch.nn.ReLU() \n",
        "        self.linear = torch.nn.Linear()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "Unet = Unet_3D()"
      ],
      "metadata": {
        "id": "R5hPg4TU66Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P2ovprvyxEeV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
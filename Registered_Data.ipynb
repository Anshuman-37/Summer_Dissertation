{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Registered_Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPHS+4mODtV9hgz9LsQU4Pj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ## On Average Takes around 12 minutes \n",
        "import os\n",
        "\n",
        "# !sudo apt -qq install file\n",
        "# !wget https://fsl.fmrib.ox.ac.uk/fsldownloads/fslinstaller.py\n",
        "# !python2 fslinstaller.py\n",
        "\n",
        "fslpath = \"/usr/local/fsl\"\n",
        "os.environ[\"FSLDIR\"] = fslpath\n",
        "os.environ[\"PATH\"] += os.pathsep + os.path.join(fslpath, 'bin')\n",
        "!. ${FSLDIR}/etc/fslconf/fsl.sh\n",
        "\n",
        "!flirt -version "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8fUWv40f0OS",
        "outputId": "53431edb-376a-481f-9581-d002c9b82ffa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLIRT version 6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PdWPPWotIeo_"
      },
      "outputs": [],
      "source": [
        "## Takes a bit time to read the kaggle . json file \n",
        "!pip install kaggle --upgrade\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!mkdir content/data\n",
        "!kaggle datasets download -d lyfeisgood/something\n",
        "!unzip /content/something.zip -d data\n",
        "!pip install regtricks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "import torch\n",
        "import regtricks\n",
        "## Import my .py file ....... \n",
        "import Data_Loader as dl\n",
        "import Models as model\n",
        "import regtricks as rt\n",
        "!pip install torchsummary\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAJAOqkdI1uP",
        "outputId": "2cb698ea-f372-4f96-a1d1-4306467b2773"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.0+cu113\n",
            "True\n",
            "1.12.0+cu113\n",
            "True\n",
            "cuda:0\n",
            "1.12.0+cu113\n",
            "True\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Take around 5 minutes\n",
        "## Defining the path of the data \n",
        "x,y = dl.data_loader('/content/data','/content/data',device)\n",
        "\n",
        "## Printing the shape of specifid data\n",
        "print('\\nShape of MRI images - >');     dl.print_data_shape(x); \n",
        "print('\\nShape of ASL images - >');     dl.print_data_shape(y);\n",
        "\n",
        "## Printing the Stats of the data\n",
        "print('\\nStats for MRI data(X) - >');   dl.tensor_stats(x); \n",
        "print('\\nStats for ASL data(X) - >');   dl.tensor_stats(y);\n",
        "\n",
        "## Printing the Dimension of X and Y  \n",
        "## Dimension refer -> Number x Length x Breadth x Height x Channel\n",
        "print('\\nDimensions of X(MRI Data) ->',end=' '); dl.print_data_dimension(x)\n",
        "print('\\nDimensions of Y(ASL Data) ->',end=' '); dl.print_data_dimension(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSGbVbDnLSWl",
        "outputId": "cc891b5d-1cbb-4da9-ec21-dc057e4ff9e7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of MRI images - >\n",
            "torch.Size([1, 91, 109, 91])\n",
            "torch.Size([1, 91, 109, 91])\n",
            "torch.Size([1, 91, 109, 91])\n",
            "torch.Size([1, 91, 109, 91])\n",
            "torch.Size([1, 91, 109, 91])\n",
            "torch.Size([1, 91, 109, 91])\n",
            "torch.Size([1, 91, 109, 91])\n",
            "torch.Size([1, 91, 109, 91])\n",
            "torch.Size([1, 91, 109, 91])\n",
            "torch.Size([1, 91, 109, 91])\n",
            "\n",
            "Shape of ASL images - >\n",
            "torch.Size([1, 91, 109, 91])\n",
            "torch.Size([1, 91, 109, 91])\n",
            "torch.Size([1, 91, 109, 91])\n",
            "torch.Size([1, 91, 109, 91])\n",
            "torch.Size([1, 91, 109, 91])\n",
            "torch.Size([1, 91, 109, 91])\n",
            "torch.Size([1, 91, 109, 91])\n",
            "torch.Size([1, 91, 109, 91])\n",
            "torch.Size([1, 91, 109, 91])\n",
            "torch.Size([1, 91, 109, 91])\n",
            "\n",
            "Stats for MRI data(X) - >\n",
            "tensor(75418.3359) tensor(0.) tensor(0.0836) tensor(0.1490)\n",
            "tensor(69193.1094) tensor(0.) tensor(0.0767) tensor(0.1362)\n",
            "tensor(85693.1250) tensor(0.) tensor(0.0949) tensor(0.1830)\n",
            "tensor(57976.9219) tensor(0.) tensor(0.0642) tensor(0.1260)\n",
            "tensor(74949.1797) tensor(0.) tensor(0.0830) tensor(0.1530)\n",
            "tensor(67629.3281) tensor(0.) tensor(0.0749) tensor(0.1523)\n",
            "tensor(95745.1406) tensor(0.) tensor(0.1061) tensor(0.1754)\n",
            "tensor(70232.4141) tensor(0.) tensor(0.0778) tensor(0.1568)\n",
            "tensor(63041.9375) tensor(0.) tensor(0.0698) tensor(0.1217)\n",
            "tensor(67808.2734) tensor(0.) tensor(0.0751) tensor(0.1417)\n",
            "\n",
            "Stats for ASL data(X) - >\n",
            "tensor(64626.6406) tensor(0.) tensor(0.0716) tensor(0.1236)\n",
            "tensor(71800.8438) tensor(0.) tensor(0.0795) tensor(0.1413)\n",
            "tensor(29862.6191) tensor(0.) tensor(0.0331) tensor(0.0610)\n",
            "tensor(38559.2734) tensor(0.) tensor(0.0427) tensor(0.0781)\n",
            "tensor(34380.5547) tensor(0.) tensor(0.0381) tensor(0.0677)\n",
            "tensor(31914.0234) tensor(0.) tensor(0.0354) tensor(0.0661)\n",
            "tensor(48238.9375) tensor(0.) tensor(0.0534) tensor(0.0972)\n",
            "tensor(76050.9375) tensor(0.) tensor(0.0843) tensor(0.1469)\n",
            "tensor(38336.3242) tensor(0.) tensor(0.0425) tensor(0.0774)\n",
            "tensor(48334.8750) tensor(0.) tensor(0.0535) tensor(0.0975)\n",
            "\n",
            "Dimensions of X(MRI Data) -> torch.Size([10, 1, 91, 109, 91])\n",
            "\n",
            "Dimensions of Y(ASL Data) -> torch.Size([10, 1, 91, 109, 91])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, LazyConv3d , MaxPool3d, Module, Softmax, BatchNorm3d, Dropout, Conv3d, MSELoss,functional \n",
        "from torch.optim import Adam, SGD\n",
        "from torchsummary import summary as tfsum \n",
        "from tqdm import tqdm\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "hidden = lambda c_in, c_out: Sequential(\n",
        "    Conv3d(c_in, c_out, (3,3,2), padding=(1,1,1)),\n",
        "    BatchNorm3d(c_out),\n",
        "    ReLU(),\n",
        "    MaxPool3d(1)\n",
        "    )\n",
        "hidden_2 = lambda c_in, c_out: Sequential(\n",
        "    Conv3d(c_in, c_out, (3,3,5),padding=(1,1,1)),\n",
        "    BatchNorm3d(c_out),\n",
        "    ReLU(),\n",
        "    MaxPool3d(1)\n",
        "    )\n",
        "Hidden = lambda c_in, c_out: Sequential(\n",
        "    Conv3d(c_in, c_out, (1,1,4)),\n",
        "    BatchNorm3d(c_out),\n",
        "    ReLU(),\n",
        "    MaxPool3d(1)\n",
        "    )\n",
        "class Model_1(Module):\n",
        "    '''Class for the Model to be fitted on MRI data'''\n",
        "    def __init__(self, c):\n",
        "        '''Intiallizing the layers of the Model'''\n",
        "        super(Model_1, self).__init__();\n",
        "        self.hidden1 = hidden(1,16*c);\n",
        "        self.hidden2 = hidden(16*c,16*c);\n",
        "        self.hidden3 = hidden(16*c,16*c);\n",
        "        self.hidden4 = hidden(16*c,16*c);\n",
        "        self.hidden5 = hidden(16*c,16*c);\n",
        "        self.hidden6 = hidden_2(16*c,16*c);\n",
        "        self.hidden7 = Hidden(16*c,1);\n",
        "    def forward(self, x):\n",
        "        '''Implements the forward pass of the Network'''\n",
        "        x = self.hidden1(x)\n",
        "        x = self.hidden2(x)\n",
        "        x = self.hidden3(x)\n",
        "        x = self.hidden4(x)\n",
        "        x = self.hidden5(x)\n",
        "        x = self.hidden6(x)\n",
        "        x = self.hidden7(x)\n",
        "        return x "
      ],
      "metadata": {
        "id": "yDEID-5wsi6l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "channels = 1; #3 Defining the number od channels we have for neural network\n",
        "# Intializing model\n",
        "torch.cuda.empty_cache()\n",
        "torch.backends.cudnn.benchmark = True\n",
        "model = Model_1(channels).to(device) # Intializing the model \n",
        "summary(model,(1, 91,109,91))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwsusM5z1AMI",
        "outputId": "f9ee692e-c929-4cad-9751-2ce3e688ddc8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1      [-1, 16, 91, 109, 92]             304\n",
            "       BatchNorm3d-2      [-1, 16, 91, 109, 92]              32\n",
            "              ReLU-3      [-1, 16, 91, 109, 92]               0\n",
            "         MaxPool3d-4      [-1, 16, 91, 109, 92]               0\n",
            "            Conv3d-5      [-1, 16, 91, 109, 93]           4,624\n",
            "       BatchNorm3d-6      [-1, 16, 91, 109, 93]              32\n",
            "              ReLU-7      [-1, 16, 91, 109, 93]               0\n",
            "         MaxPool3d-8      [-1, 16, 91, 109, 93]               0\n",
            "            Conv3d-9      [-1, 32, 91, 109, 94]           9,248\n",
            "      BatchNorm3d-10      [-1, 32, 91, 109, 94]              64\n",
            "             ReLU-11      [-1, 32, 91, 109, 94]               0\n",
            "        MaxPool3d-12      [-1, 32, 91, 109, 94]               0\n",
            "           Conv3d-13      [-1, 16, 91, 109, 95]           9,232\n",
            "      BatchNorm3d-14      [-1, 16, 91, 109, 95]              32\n",
            "             ReLU-15      [-1, 16, 91, 109, 95]               0\n",
            "        MaxPool3d-16      [-1, 16, 91, 109, 95]               0\n",
            "           Conv3d-17      [-1, 16, 91, 109, 96]           4,624\n",
            "      BatchNorm3d-18      [-1, 16, 91, 109, 96]              32\n",
            "             ReLU-19      [-1, 16, 91, 109, 96]               0\n",
            "        MaxPool3d-20      [-1, 16, 91, 109, 96]               0\n",
            "           Conv3d-21       [-1, 8, 91, 109, 94]           5,768\n",
            "      BatchNorm3d-22       [-1, 8, 91, 109, 94]              16\n",
            "             ReLU-23       [-1, 8, 91, 109, 94]               0\n",
            "        MaxPool3d-24       [-1, 8, 91, 109, 94]               0\n",
            "           Conv3d-25       [-1, 1, 91, 109, 91]              33\n",
            "      BatchNorm3d-26       [-1, 1, 91, 109, 91]               2\n",
            "             ReLU-27       [-1, 1, 91, 109, 91]               0\n",
            "        MaxPool3d-28       [-1, 1, 91, 109, 91]               0\n",
            "================================================================\n",
            "Total params: 34,043\n",
            "Trainable params: 34,043\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 3.44\n",
            "Forward/backward pass size (MB): 2986.78\n",
            "Params size (MB): 0.13\n",
            "Estimated Total Size (MB): 2990.35\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epochs,batch_size,x,y):\n",
        "        '''To train the neural network and return the losses'''\n",
        "        ctr = 0; train_loss = []; \n",
        "        lossFn = MSELoss(); opt = Adam(model.parameters(), lr=1e-5);\n",
        "        X = x.to(device); Y = y.to(device);\n",
        "        for e in tqdm(range(0, epochs)):\n",
        "            model.train(); batch_loss = [];\n",
        "            permutation = torch.randperm(X.size()[0])\n",
        "            for i in range(0,X.size()[0], batch_size):\n",
        "                opt.zero_grad();\n",
        "                indices = permutation[i:i+batch_size];\n",
        "                batch_x, batch_y = X[indices], Y[indices];\n",
        "                pred = model(batch_x) ; loss = lossFn(pred, batch_y);\n",
        "                loss.backward(); opt.step();\n",
        "                batch_loss.append(loss); \n",
        "            train_loss.append(batch_loss);\n",
        "            if(e%10 == 0): print(loss); \n",
        "            ctr = ctr+1; \n",
        "            if ctr < epochs-1:\n",
        "                del loss , pred\n",
        "        return train_loss, pred;\n",
        "train_loss,prediction = train(210,3,x,y);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "id": "f2xU3MXdVxRB",
        "outputId": "75b256a5-7b00-4011-d6e3-22551223a2e1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/250 [00:09<39:50,  9.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.2536, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 11/250 [00:30<08:58,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1828, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 21/250 [00:52<08:21,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1345, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 31/250 [01:13<07:59,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1263, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▋        | 41/250 [01:34<07:37,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0906, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 51/250 [01:55<07:15,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0792, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 61/250 [02:16<06:53,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0642, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 71/250 [02:38<06:31,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0476, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 81/250 [02:59<06:09,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0491, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▋      | 91/250 [03:20<05:47,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 101/250 [03:41<05:26,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0360, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 111/250 [04:02<05:04,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 121/250 [04:24<04:42,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 131/250 [04:45<04:20,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▋    | 141/250 [05:06<03:58,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 151/250 [05:27<03:36,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 161/250 [05:48<03:14,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0149, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 171/250 [06:10<02:53,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 181/250 [06:31<02:30,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▋  | 191/250 [06:52<02:09,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0109, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 201/250 [07:13<01:47,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0095, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 211/250 [07:35<01:25,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 219/250 [07:54<01:07,  2.16s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1a86906681c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-1a86906681c8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, batch_size, x, y)\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m;\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossFn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 15.90 GiB total capacity; 12.92 GiB already allocated; 89.75 MiB free; 14.90 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import regtricks as rt\n",
        "# str2asl_reg=rt.flirt(src=x[0],ref=y[0])\n",
        "# xD=str2asl_reg.apply_to_image(x[0],ref=y[0])"
      ],
      "metadata": {
        "id": "50M6gKJWWC21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def data_prep(mri_data_dict,asl_data_dict,device):\n",
        "#     '''\n",
        "#     Params - Dictionary of MRI Data, ASL data and the device to which the tensors are stored\n",
        "#     Result - Creates tensors from the data dictionary feeded\n",
        "#     '''\n",
        "#     x = [] ; y = []; X = []; Y = [];\n",
        "#     for k,v in mri_data_dict.items():\n",
        "#         if k in asl_data_dict:\n",
        "#             # Loading the MRI image from the path in the train x path \n",
        "#             mri_img_x = nib.load(v); asl_img = nib.load(asl_data_dict[k]); str2asl_reg=rt.flirt(src=mri_img_x,ref=asl_img)\n",
        "#             mri_img =  str2asl_reg.apply_to_image(mri_img_x,ref=asl_img)\n",
        "#             # Making it a numpy array\n",
        "#             mri_vec = np.array(mri_img.dataobj)[np.newaxis,:,:,:] # Channels x Length X Breadth X Slices of Brain\n",
        "#             # Min max Normalizing the image \n",
        "#             mri_vec = (mri_vec - mri_vec.min()) / (mri_vec.max() - mri_vec.min())\n",
        "#             # Appending the MRI image to X \n",
        "#             x.append(torch.as_tensor(mri_vec,dtype=torch.float32));#.to(device)); \n",
        "#             ## Finding the same patient with ASL data \n",
        "#             asl_img = nib.load(asl_data_dict[k]); asl_vec = np.array(asl_img.dataobj)[np.newaxis,:,:,:]; \n",
        "#             asl_vec = (asl_vec - asl_vec.min()) / (asl_vec.max() - asl_vec.min());\n",
        "#             ## Appending the image to y\n",
        "#             y.append(torch.as_tensor(asl_vec,dtype=torch.float32));#.to(device))\n",
        "#             X = torch.stack(x,dim=0)#.to(device);\n",
        "#             Y = torch.stack(y,dim=0)#.to(device);\n",
        "#     return X,Y"
      ],
      "metadata": {
        "id": "iI0M6PhdY2s5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Takes 4 minutes\n",
        "# mri,asl = dl.create_data_dict(dl.get_mri_data('/content/data'),dl.get_asl_data('/content/data'))\n",
        "# x,y = data_prep(mri,asl,device)"
      ],
      "metadata": {
        "id": "lC1jKeHkZJ3J"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dl.print_data_dimension(x); dl.print_data_dimension(y);\n",
        "\n",
        "x_first = prediction[0]\n",
        "pred_np = x_first.cpu().detach().numpy()\n",
        "dl.print_data_dimension(pred_np); print(type(pred_np))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "img = [] # some array of images\n",
        "frames = [] # for storing the generated images\n",
        "fig = plt.figure()\n",
        "for i in range(0,x.shape[4]):\n",
        "    ## For L2 Distance\n",
        "    frames.append([plt.imshow(pred_np[0,:,:,i], cmap=cm.Greys_r,animated=True)])\n",
        "ani = animation.ArtistAnimation(fig, frames, interval=120, blit=True, repeat_delay=1000)\n",
        "ani.save('movie.mp4')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "LtfUfa9CZhae",
        "outputId": "1dc33ad7-dce0-4a03-ca74-1328f57c6c0e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-33978c5b972d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# dl.print_data_dimension(x); dl.print_data_dimension(y);\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpred_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_first\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_data_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'prediction' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('/content/movie.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "metadata": {
        "id": "mAc5kwCWnd9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_7srqwbdumDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#train_loss,prediction = train(2,3,train_x,train_y);\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "iF6ogAvysH-J",
        "outputId": "52affc9a-9c1f-446a-b6a1-523749fdae3d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1b49f4c48748>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9RQ4efYlsIFF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}